{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Diffusion Model - Model prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib.colors import Normalize\n",
    "import datetime\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# for some fucking reason linspace dont work on GPU, who tf knows\n",
    "def linspace(*args):\n",
    "    with tf.device('/CPU:0'):\n",
    "        return tf.linspace(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current path\n",
    "current_path = Path(\"C:/Users/brain/My Drive (brain@roforco.com)/CodeInDocs/MyDiffusionModel/notebooks/model_prototyping.ipynb\").resolve()\n",
    "\n",
    "#Load the data\n",
    "data = np.load(current_path.parent.parent / \"data\" / \"sprites_1788_16x16.npy\")\n",
    "print(data.shape)\n",
    "\n",
    "#Shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#plot data\n",
    "fig, axes = plt.subplots(5,5, figsize=(10,10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion hyperparameters\n",
    "timesteps = 500\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# construct DDPM noise schedule\n",
    "b_t = (beta2 - beta1) * linspace(0, 1, timesteps + 1) + beta1\n",
    "b_t = tf.cast(b_t, tf.float32)  # Ensure b_t is float32\n",
    "a_t = 1 - b_t\n",
    "a_t = tf.cast(a_t, tf.float32)  # Ensure a_t is float32\n",
    "ab_t = tf.exp(tf.cumsum(tf.math.log(a_t), axis=0))\n",
    "ab_t = tf.concat([[1.0], ab_t[1:]], axis=0)\n",
    "ab_t = tf.cast(ab_t, tf.float32) # Ensure ab_t is float32\n",
    "\n",
    "print(ab_t.shape)\n",
    "print(ab_t[:10])\n",
    "print(ab_t[1])\n",
    "\n",
    "#Save directory for the weights\n",
    "save_dir = current_path.parent.parent / \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Ensures reproducibility for certain hash-based operations\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "set_seed(245987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualConvBlock(in_channels, out_channels, is_res = False, kernel_size=3, stride=1, padding=\"same\", name = \"ResidualConvBlock\"):\n",
    "    \"\"\"A Conv block with \"possible\" residual connection\n",
    "    Args:\n",
    "        shape (tuple): shape of the input tensor [ (height, width, channels) without including the batch size. ]\n",
    "        out_channels (int): number of output channels\n",
    "        is_res (bool, optional): whether to use residual connection or not\n",
    "        kernel_size (int, optional): Defaults to 3.\n",
    "        stride (int, optional): Defaults to 1.\n",
    "        padding (str, optional): Defaults to \"same\".\n",
    "    Returns:\n",
    "        functional keras Model: ResidualConvBlock\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(None,None,in_channels), name = \"ResidualConvBlock_input\")\n",
    "    \n",
    "    # First Convolutional Layer\n",
    "    x = layers.Conv2D(out_channels, kernel_size, stride, padding)(inputs) # channels last by default\n",
    "    x = layers.BatchNormalization(axis=-1)(x)\n",
    "    x = layers.Activation(tf.nn.gelu)(x)\n",
    "    \n",
    "    # Second Convolutional Layer\n",
    "    x = layers.Conv2D(out_channels, kernel_size, stride, padding)(x)\n",
    "    x = layers.BatchNormalization(axis=-1)(x)\n",
    "    x = layers.Activation(tf.nn.gelu)(x)\n",
    "    \n",
    "    # Add the residual connection specified\n",
    "    if is_res:\n",
    "        if in_channels == out_channels:\n",
    "            # if the number of channels is the same, we can add the shortcut directly\n",
    "            x = layers.Add()([x, inputs])\n",
    "        else:\n",
    "            # if the number of channels is different, translate the shortcut to the right number of channels through a 1x1 convolution\n",
    "            translated_inputs = layers.Conv2D(out_channels, 1, 1, padding)(inputs)\n",
    "            x = layers.Add()([x, translated_inputs])\n",
    "            \n",
    "        # Scale by sqrt(0.5) to normalize the variance\n",
    "        x = layers.Lambda(lambda x: x / 1.414)(x)\n",
    "\n",
    "    ResidualConvBlock = keras.Model(inputs=inputs, outputs=x, name=name)\n",
    "    # ResidualConvBlock.summary()\n",
    "    # keras.utils.plot_model(ResidualConvBlock, \"ConvBlock.png\", show_shapes=True)\n",
    "    \n",
    "    return ResidualConvBlock\n",
    "\n",
    "# TEST CODE FOR ResidualConvBlock\n",
    "# Res = ResidualConvBlock(3, 64, is_res=True)\n",
    "# Res2 = ResidualConvBlock(3, 64, is_res=False)\n",
    "# # Res2.set_weights(Res.get_weights())\n",
    "# out = Res(tf.ones((1,16,16,3)))\n",
    "# out2 = Res2(tf.ones((1,16,16,3)))\n",
    "# print(out[0][0][0])\n",
    "# print(out2[0][0][0])\n",
    "\n",
    "def Encoder(in_channels, out_channels, name = \"Encoder\"):\n",
    "    \"\"\"Encoder block for Unet\n",
    "    Args:\n",
    "        out_channels (int): number of output channels\n",
    "    Returns:\n",
    "        keras functional Model: Encoder\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(None,None,in_channels), name = \"Encoder_input\")\n",
    "    x = ResidualConvBlock(in_channels, out_channels, name=\"ResidualConvBlock1\")(inputs)\n",
    "    x = ResidualConvBlock(out_channels, out_channels, name=\"ResidualConvBlock2\")(x)\n",
    "    x = layers.MaxPooling2D(strides=2)(x)\n",
    "    Encoder = keras.Model(inputs=inputs, outputs=x, name=name)\n",
    "    # Encoder.summary()\n",
    "    \n",
    "    return Encoder\n",
    "\n",
    "# TEST CODE FOR Encoder\n",
    "# e = Encoder(3, 64)\n",
    "# out = e(tf.ones((1,16,16,3)))\n",
    "# print(out.shape)\n",
    "\n",
    "def Decoder(in_channels, out_channels, name = \"Decoder\"):\n",
    "    \"\"\"Decoder block for Unet\n",
    "    Args:\n",
    "        in_channels (int): TOTAL: input_channels + skip_channels\n",
    "        out_channels (int): number of output channels\n",
    "    Returns:\n",
    "        Keras Model: Decoder\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(None,None,int(in_channels/2)), name = \"Decoder_input\")\n",
    "    skip_connection = keras.Input(shape=(None,None,int(in_channels/2)), name = \"Decoder_skip_connection\")\n",
    "    \n",
    "    x = layers.Concatenate()([inputs, skip_connection]) # axis = -1 default\n",
    "    x = layers.Conv2DTranspose(out_channels, 2, 2)(x) # filters, kernel_size, strides\n",
    "    x = ResidualConvBlock(out_channels, out_channels, name=\"ResidualConvBlock1\")(x)\n",
    "    x = ResidualConvBlock(out_channels, out_channels, name=\"ResidualConvBlock2\")(x)\n",
    "    \n",
    "    Decoder = keras.Model(inputs=[inputs, skip_connection], outputs=x, name=name)\n",
    "    # Decoder.summary()\n",
    "    \n",
    "    return Decoder\n",
    "\n",
    "# TEST CODE FOR Decoder\n",
    "# d = Decoder(256, 64)\n",
    "# out = d([tf.ones((1,4,4,128)), tf.ones((1,4,4,128))])\n",
    "# print(out.shape)\n",
    "\n",
    "def TimeEmbeddingBlock(out_channels):\n",
    "    \"\"\"Time Embedding block for Unet\n",
    "    Args:\n",
    "        out_channels (int): number of output channels\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(1,), name = \"TimeEmbedding_input\")\n",
    "    x = layers.Dense(out_channels)(inputs)\n",
    "    x = layers.Activation(tf.nn.gelu)(x)\n",
    "    x = layers.Dense(out_channels)(x)\n",
    "    x = layers.Reshape((1,1,-1))(x)\n",
    "    \n",
    "    TimeEmbeddingBlock = keras.Model(inputs=inputs, outputs=x, name=\"TimeEmbeddingBlock\")\n",
    "    # TimeEmbeddingBlock.summary()\n",
    "    \n",
    "    return TimeEmbeddingBlock\n",
    "\n",
    "# TEST CODE FOR TimeEmbeddingBlock\n",
    "# print(TimeEmbeddingBlock(128)(tf.ones((1,1))).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_model(keras.Model):\n",
    "\n",
    "    def __init__(self, in_channels, nC = 64, height=16, skip = True, dropout_rate=[0.1,0.2,0.3,0.4]):  \n",
    "        \"\"\"innitializes Unet\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of channels in input image, RGB = 3\n",
    "            nC (int, optional): how many channels hidden channels in the first encoding step. Defaults to 64.\n",
    "            height (int, optional): height of image. (must be factor of 4) Defaults to 16.\n",
    "            dropout_rate (list, optional): dropout rate for each layer LEVEL, 4 total lvl1 = innitial, lvl4 = bottleneck. Defaults to [0.1,0.2,0.3,0.4].\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.nC = nC\n",
    "        self.h = height\n",
    "        self.skip = skip\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Rescale the input image to [-1, 1]\n",
    "        self.rescaling = layers.Rescaling(1./127.5, offset = -1, input_shape=(height, height, in_channels))\n",
    "        \n",
    "        # Initialize the Encoder\n",
    "        self.innitial_block = ResidualConvBlock(in_channels, nC, name=\"innitial_block\", is_res=True) # 16, 16, nC\n",
    "        self.dropout0 = layers.Dropout(dropout_rate[0])\n",
    "        \n",
    "        #Encover 1 and 2\n",
    "        self.e1 = Encoder(nC, nC, name = \"Encoder1\") # 8, 8, nC\n",
    "        self.dropout1 = layers.Dropout(dropout_rate[1])\n",
    "        self.e2 = Encoder(nC, 2*nC, name = \"Encoder2\") # 4, 4, 2nC\n",
    "        self.dropout2 = layers.Dropout(dropout_rate[2])\n",
    "        \n",
    "        # Encoder output, reducing to 1x1 spatial resolution\n",
    "        self.encoder_output = keras.Sequential([ # 1, 1, 2nC\n",
    "            layers.AveragePooling2D(height//4), \n",
    "            layers.Activation(tf.nn.gelu),\n",
    "            layers.Dropout(dropout_rate[3]),\n",
    "        ], name = \"Encoder_output\") \n",
    "        \n",
    "        #Bottleneck\n",
    "        self.bottleneck = keras.Sequential([ # 4, 4, 2nC\n",
    "            layers.Conv2DTranspose(2*nC, int(height/4), int(height/4)), # filters, kernel_size, strides\n",
    "            tfa.layers.GroupNormalization(groups=8),\n",
    "            layers.Activation(tf.nn.relu),\n",
    "            layers.Dropout(dropout_rate[3]),\n",
    "        ], name = \"Bottleneck\") \n",
    "        \n",
    "        # Time embeddings\n",
    "        self.time_embedding1 = TimeEmbeddingBlock(2*nC) # 1, 1, 2nC\n",
    "        self.time_embedding2 = TimeEmbeddingBlock(nC) # 1, 1, nC\n",
    "        \n",
    "        # Decoder 1 and 2\n",
    "        self.d1 = Decoder(4*nC, nC, name = \"Decoder1\") # 4, 4, 4nC -> 8, 8, nC\n",
    "        self.d2 = Decoder(2*nC, nC, name = \"Decoder2\") # 8, 8, 2nC -> 16, 16, nC\n",
    "        \n",
    "        #Output Layer\n",
    "        self.output_layer = keras.Sequential([ # 16, 16, 2nC -> 16, 16, nC ->16, 16, in_channels\n",
    "            layers.Conv2D(nC, 3, 1, \"same\"),\n",
    "            tfa.layers.GroupNormalization(groups=8),\n",
    "            layers.Activation(tf.nn.relu),\n",
    "            # layers.Dropout(dropout_rate[0]), #Might remove\n",
    "            layers.Conv2D(in_channels, 3, 1, \"same\"),\n",
    "        ], name = \"OutputLayer\") \n",
    "        \n",
    "    @tf.function  \n",
    "    def call(self, images, t=tf.constant([0.0]), training=False):\n",
    "        \"\"\"forward pass of Unet\n",
    "        Args:\n",
    "            images : (batch, h, w, channels) : input image\n",
    "            t : tensor(batch, 1)      : fraction: current time step / total timesteps\n",
    "\n",
    "        Returns:\n",
    "            out: (batch, in_channels, h, w) : ouptut of Unet\n",
    "        \"\"\"\n",
    "        \n",
    "        # apply rescaling to [-1, 1] if image is currenctly in [0, 255]\n",
    "        if images.dtype == tf.uint8:\n",
    "            images = self.rescaling(images)\n",
    "        # tf.print(f\"max: {tf.reduce_max(images)}, min: {tf.reduce_min(images)}\")\n",
    "        \n",
    "        # innilialize the encoder\n",
    "        innitial = self.innitial_block(images, training=training) # 16, 16, nC\n",
    "        dropped0 = self.dropout0(innitial, training=training)\n",
    "        \n",
    "        # Encoder 1 and 2\n",
    "        e1 = self.e1(dropped0, training=training) # 8, 8, nC\n",
    "        dropped1 = self.dropout1(e1, training=training)\n",
    "        \n",
    "        e2 = self.e2(dropped1, training=training) # 4, 4, 2nC\n",
    "        dropped2 = self.dropout2(e2, training=training)\n",
    "        \n",
    "        # Encoder output\n",
    "        encoder_output = self.encoder_output(dropped2, training=training) # 1, 1, 2nC\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(encoder_output, training=training) # 4, 4, 2nC\n",
    "        \n",
    "        # Time embeddings\n",
    "        time_embedding1 = self.time_embedding1(t) # 1, 1, 2nC\n",
    "        time_embedding2 = self.time_embedding2(t) # 1, 1, nC\n",
    "        \n",
    "        # Decoder 1 and 2\n",
    "        d1 = self.d1([bottleneck + time_embedding1, e2], training=training) # 8, 8, nC\n",
    "        dropped3 = self.dropout2(d1, training=training)\n",
    "        \n",
    "        d2 = self.d2([dropped3 + time_embedding2, e1], training=training) # 16, 16, nC\n",
    "        dropped4 = self.dropout1(d2, training=training)\n",
    "        \n",
    "        # Output Layer\n",
    "        if self.skip:\n",
    "            concatenated = tf.concat([dropped4, innitial], axis=-1) # 16, 16, 2nC\n",
    "            out = self.output_layer(concatenated, training=training) # 16, 16, in_channels\n",
    "        else: \n",
    "            out = self.output_layer(dropped4, training=training) # 16, 16, in_channels\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            data (tensor): images of shape (batch, h, w, channels)\n",
    "                format: ( (all x passed in fit) , (all y passed in fit) ) \n",
    "                multiple data points passed in fit as tuples or array: .fit( (x1,x2), y, batch_size=1, epochs=1)\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        x = data\n",
    "\n",
    "        # rescalse the input to [-1, 1] if it is in [0, 255]\n",
    "        if x.dtype == tf.uint8:\n",
    "            x = self.rescaling(x)\n",
    "\n",
    "        # add random noise at random t to the current batch of images\n",
    "        noise = tf.random.normal(tf.shape(x)) # random noise for each image in the batch\n",
    "        t = tf.random.uniform((tf.shape(x)[0],), minval=0, maxval=timesteps+1, dtype=tf.int32) # random t for each image in the batch\n",
    "        x_pert = perturb_input(x, t, noise)\n",
    "        \n",
    "        t_fraction = tf.cast(t / timesteps, dtype=tf.float32)\n",
    "        t_fraction = tf.reshape(t_fraction, (-1,1))\n",
    "\n",
    "        # calculate loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_noise = self(x_pert, t_fraction, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compute_loss(y=noise, y_pred=pred_noise)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(noise, pred_noise)\n",
    "                \n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "\n",
    "        # rescalse the input to [-1, 1] if it is in [0, 255]\n",
    "        if x.dtype == tf.uint8:\n",
    "            x = self.rescaling(x)\n",
    "        \n",
    "        # add random noise at random t to the current batch of images\n",
    "        noise = tf.random.normal(tf.shape(x))\n",
    "        t = tf.random.uniform((tf.shape(x)[0],), minval=0, maxval=timesteps+1, dtype=tf.int32) # random t for each image in the batch\n",
    "        x_pert = perturb_input(x, t, noise)\n",
    "\n",
    "        t_fraction = tf.cast(t / timesteps, dtype=tf.float32)\n",
    "        t_fraction = tf.reshape(t_fraction, (-1,1))\n",
    "\n",
    "        # get prediction\n",
    "        pred_noise = self(x_pert, t_fraction, training=False)\n",
    "        \n",
    "        loss = self.compiled_loss(noise, pred_noise)\n",
    "        self.compiled_metrics.update_state(noise, pred_noise)\n",
    "        \n",
    "        # tf.print(f\"Batch Loss: {loss}\")\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# TEST CODE FOR Unet_model\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "dummy_data = data[:10]\n",
    "\n",
    "test_Unet = Unet_model(3)\n",
    "_ = test_Unet(keras.Input(shape=(16,16,3)), keras.Input(shape=(1,)))\n",
    "test_Unet.summary()\n",
    "\n",
    "t = tf.random.uniform((tf.shape(dummy_data)[0],), minval=0, maxval=3, dtype=tf.int32) # random t for each image in the batch\n",
    "t = tf.cast(t / timesteps, dtype=tf.float32)\n",
    "print(t)\n",
    "t = tf.reshape(t, (-1,1))  \n",
    "\n",
    "out = test_Unet(dummy_data, t)\n",
    "\n",
    "print(out.shape)\n",
    "plt.imshow(out[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: perturbs an image to a specified noise level\n",
    "def perturb_input(x, t, noise):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "        t (_type_): _description_\n",
    "        noise (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        perturbed image: (batch, h, w, channels) computed with (#t, 1, 1, 1)\n",
    "            ex. t = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \"\"\"\n",
    "    \n",
    "    gathered = tf.gather(ab_t, t)\n",
    "    \n",
    "    a = tf.sqrt(gathered)\n",
    "    a = tf.reshape(a, (-1, 1, 1, 1))\n",
    "    # print(f\"a: {a[:2]}\")\n",
    "    \n",
    "    b = 1.0 - gathered\n",
    "    b = tf.reshape(b, (-1, 1, 1, 1))\n",
    "    # print(f\"b: {b[:2]}\")\n",
    "\n",
    "    return a * x + b * noise\n",
    "\n",
    "\n",
    "# x = data[:10]\n",
    "# t = tf.random.uniform((tf.shape(x)[0],), minval=0, maxval=2, dtype=tf.int32)\n",
    "# noise = tf.random.normal(tf.shape(x))\n",
    "\n",
    "# print(t)\n",
    "# print(tf.gather(ab_t, t))\n",
    "\n",
    "# perturb_test = perturb_input(x, t, noise)\n",
    "\n",
    "# print(x[0][0][0])\n",
    "# print(x[1][0][0])\n",
    "# print(noise[0][0][0])\n",
    "# print(noise[1][0][0])\n",
    "# print(perturb_test[0][0][0])\n",
    "# print(perturb_test[1][0][0])\n",
    "\n",
    "# @tf.function\n",
    "# def test_func():\n",
    "#     t = tf.random.uniform((), 0, timesteps+1, dtype=tf.int32)\n",
    "#     print(f\"tracing {t}\")\n",
    "#     ab = ab_t[t]\n",
    "#     x = tf.constant(1, dtype=tf.float32)\n",
    "#     noise = tf.constant(1, dtype=tf.float32)\n",
    "#     p = perturb_input(x, t, noise)\n",
    "#     return ab, p, t\n",
    "    \n",
    "# ab1, p1, t1 = test_func()\n",
    "# ab2, p2, t2 = test_func()\n",
    "\n",
    "# real_ab1 = ab_t[t1]\n",
    "# real_ab2 = ab_t[t2]\n",
    "# real_p1 = perturb_input(tf.constant(1, dtype=tf.float32), t1, tf.constant(1, dtype=tf.float32))\n",
    "# real_p2 = perturb_input(tf.constant(1, dtype=tf.float32), t2, tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "# print(t1, ab1, p1)\n",
    "# print(t2, ab2, p2)\n",
    "# print(t1, real_ab1, real_p1)\n",
    "# print(t2, real_ab2, real_p2)\n",
    "\n",
    "# concrete_function = test_func.get_concrete_function()\n",
    "\n",
    "# logdir = \"logs/fit/\"\n",
    "# writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# # Log the graph to TensorBoard\n",
    "# with writer.as_default():\n",
    "#     tf.summary.graph(concrete_function.graph)\n",
    "#     writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(98234567)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "def build_hypermodel(hp, total_samples=data_subset.shape[0]*0.8):\n",
    "    nC = hp.Int('nC', min_value=40, max_value=112, step=24) # 40, 64, 88, 112\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log') # 0.0001, 0.01\n",
    "    # end_lr = hp.Float('end_learning_rate', min_value=1e-12, max_value=1e-8, sampling='log')\n",
    "    batch_size = hp.Int('batch_size', min_value=50, max_value=150, step=50)\n",
    "    # skip = hp.Boolean(\"skip connection\")\n",
    "    dropout_rates = [\n",
    "        hp.Float('dropout_rate_0', min_value=0.0, max_value=0.3, step=0.05),\n",
    "        hp.Float('dropout_rate_1', min_value=0.0, max_value=0.4, step=0.05),\n",
    "        hp.Float('dropout_rate_2', min_value=0.0, max_value=0.5, step=0.05),\n",
    "        hp.Float('dropout_rate_3', min_value=0.0, max_value=0.6, step=0.05)\n",
    "    ]\n",
    "    \n",
    "    steps_per_epoch = total_samples // batch_size # Calculate the number of steps / batches per epoch\n",
    "    decay_steps = steps_per_epoch * n_epoch # Number of steps to decay over\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=lr,\n",
    "        decay_steps=decay_steps,\n",
    "        end_learning_rate=0,\n",
    "        power=1.0)\n",
    "    \n",
    "    model = Unet_model(3, nC=nC, dropout_rate=dropout_rates)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "    )\n",
    "    model.batch_size = batch_size\n",
    "    return model\n",
    "\n",
    "class MyBayesianOptimization(kt.BayesianOptimization):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "        model = self.hypermodel.build(hp)\n",
    "\n",
    "        checkpoint_filepath = f'tuning_results/{project_name}/trial_{trial.trial_id}/cp-{{epoch:04d}}.ckpt'\n",
    "        log_dir = \"logs/fit/\" + f\"{project_name}-trial-{trial.trial_id}\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                min_delta=1e-4,\n",
    "                patience=4,\n",
    "                verbose=1,\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=True,\n",
    "                save_best_only=True,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                verbose=1\n",
    "            ),\n",
    "            tensorboard_callback\n",
    "        ]\n",
    "\n",
    "        # Fit with the provided arguments\n",
    "        with tf.device('/GPU:0'):\n",
    "            history = model.fit(*args, batch_size=model.batch_size, callbacks=callbacks, **kwargs)\n",
    "\n",
    "        val_loss = history.history['val_loss'][-1] # Retrieve the validation loss\n",
    "        return val_loss\n",
    "\n",
    "#Create new tuner directory\n",
    "project_name=current_time + \"-v3_Bayesian\"\n",
    "\n",
    "#Get old tuner states / directories \n",
    "# project_name=\"20240621-202942\"\n",
    "\n",
    "tuner = MyBayesianOptimization(\n",
    "    hypermodel=build_hypermodel,\n",
    "    max_trials=50,\n",
    "    overwrite=False,\n",
    "    directory=\"tuning_results\",\n",
    "    project_name=project_name,\n",
    ")\n",
    "\n",
    "# tuner.reload()\n",
    "\n",
    "# tuner.search_space_summary()\n",
    "\n",
    "tuner.search(data_subset, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best models\n",
    "# best_models = tuner.get_best_models(num_models=1)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(6)\n",
    "# best_model = build_hypermodel(best_hps[0])\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "n_epoch = 32\n",
    "\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "height = 16 # 16x16 image\n",
    "\n",
    "np.random.shuffle(data)\n",
    "data_subset = data[:20000]\n",
    "\n",
    "validation_split = 0.2\n",
    "total_samples = data.shape[0] * (1-validation_split) # Total number of samples in the dataset that will be trained on (exclude val set)\n",
    "steps_per_epoch = total_samples // batch_size # Calculate the number of steps / batches per epoch\n",
    "decay_steps = steps_per_epoch * n_epoch # Number of steps to decay over\n",
    "\n",
    "lrate=1e-3  # Start learning rate\n",
    "end_lrate = 0     # End learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=lrate,\n",
    "    decay_steps=decay_steps,\n",
    "    end_learning_rate=end_lrate,\n",
    "    power=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Full Training Run\n",
    "\n",
    "Single full training run using predefined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        print(f\"iterations: {self.model.optimizer.iterations}\")\n",
    "        print(f\"mylearning rate: {self.model.optimizer.lr(self.model.optimizer.iterations)}\")\n",
    "        print(f\"Epoch {epoch+1}: Learning rate is {lr.numpy()}\")\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        print(f\"iterations: {self.model.optimizer.iterations}\")\n",
    "        print(f\"Epoch {epoch+1} end: Learning rate is {lr.numpy()}\")\n",
    "\n",
    "# Training run variables/settings\n",
    "batch_name = \"custom_model3\"\n",
    "tf.config.run_functions_eagerly(False)    \n",
    "# set_seed(98234567)\n",
    "    \n",
    "#Pre-run setups\n",
    "np.random.shuffle(data)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# logging\n",
    "log_dir = \"logs/fit/\" + current_time + f\"-{batch_name}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_filepath = f'checkpoints/{batch_name}/cp-{{epoch:04d}}.ckpt'\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-4,\n",
    "        patience=4,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tensorboard_callback,\n",
    "    # LearningRateLogger()\n",
    "]\n",
    "\n",
    "#Create model\n",
    "custom_model = Unet_model(3, nC=n_feat, dropout_rate=[0.0, 0.0, 0.0, 0.0])\n",
    "custom_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = custom_model.fit(data, \n",
    "            batch_size=batch_size,\n",
    "            epochs=n_epoch, \n",
    "            verbose=1, \n",
    "            validation_split=validation_split, \n",
    "            callbacks=callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Full training runs\n",
    "\n",
    "Based on the hyperparameters found during tuning, runs through all parameters in \"best_hps\" and does a full run for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training run variables\n",
    "v3_fixedgraph = [] # the variable the models will be stored in\n",
    "batch_name = \"v3\" # the name used to save the model checkpoints in files\n",
    "\n",
    "set_seed(98234567)\n",
    "tf.config.run_functions_eagerly(False)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "for i,hp in enumerate(best_hps):\n",
    "    print(f\"Training model {i}\")\n",
    "\n",
    "    log_dir = \"logs/fit/\" + current_time + f\"-{batch_name}-model-{i}\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    checkpoint_filepath = f'checkpoints/{batch_name}/model-{i}/cp-{{epoch:04d}}.ckpt'\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=1e-4,\n",
    "            patience=4,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    "    \n",
    "    validation_split = 0.2\n",
    "    total_samples = data.shape[0] * (1-validation_split) # Total number of samples in the dataset that will be trained on (exclude val set)\n",
    "    model = build_hypermodel(hp, total_samples=total_samples)\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(data, \n",
    "                batch_size=model.batch_size,\n",
    "                epochs=32, \n",
    "                verbose=1, \n",
    "                validation_split=validation_split, \n",
    "                callbacks=callbacks\n",
    "                )\n",
    "    \n",
    "    v3_fixedgraph.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to use tensorboard\n",
    "\n",
    "# Dont use notebook commands, they suck, use cmd\n",
    "\n",
    "# Start command:\n",
    "#   tensorboard --logdir \"C:/Users/brain/My Drive (brain@roforco.com)/CodeInDocs/MyDiffusionModel/notebooks/logs/fit\"\n",
    "\n",
    "# Deleting lingering programs if not closed properly\n",
    "#   tasklist | findstr tensorboard\n",
    "#   taskkill /IM tensorboard.exe /F\n",
    "\n",
    "# If says \"Duplicate plugins for name projector\"\n",
    "#   Go in file explorer and delete the -ensorboard folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_test_models = v2_proper_lr # array of models, the models to be tested, \n",
    "\n",
    "test_dataset = data[:500]\n",
    "debug_renders = [] # [x, x_scaled, noise, x_pert, pred_noise]\n",
    "test_timesteps = []\n",
    "test_losses = []\n",
    "\n",
    "def custom_evaluate(model, loss_function, test_dataset, name=\"\"):\n",
    "    total_loss = 0\n",
    "    model.training = False\n",
    "    print(test_dataset.shape)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        for i,x in enumerate(test_dataset):   # x: images \n",
    "\n",
    "            x = x.reshape(1, 16, 16, 3)\n",
    "            debug_renders.append(x[0])\n",
    "            \n",
    "            # rescalse the input to [-1, 1] if it is in [0, 255]\n",
    "            if x.dtype == tf.uint8:\n",
    "                x = model.rescaling(x)\n",
    "            debug_renders.append(x[0])\n",
    "\n",
    "            # add random noise at random t to the current batch of images\n",
    "            noise = tf.random.normal(tf.shape(x))\n",
    "            debug_renders.append(noise[0])\n",
    "            t = np.random.randint(0, timesteps+1)\n",
    "            test_timesteps.append(t)\n",
    "            x_pert = perturb_input(x, t, noise)\n",
    "            debug_renders.append(x_pert[0])\n",
    "            \n",
    "            # use network to recover noise\n",
    "            pred_noise = model(x_pert, tf.constant([t/timesteps], dtype=tf.float32), training=False)  # Forward pass\n",
    "            debug_renders.append(pred_noise[0])\n",
    "\n",
    "            # Define the Loss Function\n",
    "            loss = loss_function(noise, pred_noise)\n",
    "            test_losses.append(loss)\n",
    "            print(loss)\n",
    "            total_loss += loss\n",
    "            \n",
    "            print(f\"Model: {name}, Step: {i} compiled_loss: {total_loss/test_dataset.shape[0]}\", end='\\r')\n",
    "            # break\n",
    "    total_loss /= test_dataset.shape[0]\n",
    "    \n",
    "    print(f\"Model: {name}, final total_loss: {total_loss}\")\n",
    "    return total_loss\n",
    "\n",
    "for i,m in enumerate(custom_test_models):\n",
    "    custom_evaluate(m, keras.losses.MeanSquaredError(), test_dataset, name=f\"{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set_seed(245987)\n",
    "\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "custom_model.evaluate(data, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_dir, name):\n",
    "    \"\"\"Saving the weights and config of a model\n",
    "\n",
    "    Args:\n",
    "        model (model): model to be saved\n",
    "        save_dir (dir): main directory to save the model\n",
    "        name (str): name of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    models_dir = save_dir / name\n",
    "    model.save_weights(f\"{models_dir}/model_0\")\n",
    "    model_config = {\n",
    "        \"nC\": model.nC,\n",
    "        \"dropout_rate\": model.dropout_rate,\n",
    "        \"skip\": model.skip,\n",
    "    }\n",
    "    with open(os.path.join(models_dir, f'model_0_config.json'), 'w') as f:\n",
    "        json.dump(model_config, f)\n",
    "        \n",
    "def save_multiple_models(models, save_dir, group_name):\n",
    "    \"\"\"Saving the weights and config of multiple models\n",
    "\n",
    "    Args:\n",
    "        models (array): array of models to be saved\n",
    "        save_dir (dir): main directory to save the models\n",
    "        group_name (str): name of the group of models\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    models_dir = save_dir / group_name\n",
    "    for i,m in enumerate(models):\n",
    "        m.save_weights(f\"{models_dir}/model_{i}\")\n",
    "        model_config = {\n",
    "            \"nC\": m.nC,\n",
    "            \"dropout_rate\": m.dropout_rate,\n",
    "            \"skip\": m.skip,\n",
    "        }\n",
    "        with open(os.path.join(models_dir, f'model_{i}_config.json'), 'w') as f:\n",
    "            json.dump(model_config, f)\n",
    "\n",
    "save_dir = current_path.parent.parent / \"weights\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_dir, num, hp = None, epoch=None):\n",
    "    \"\"\"Loading the weights and config of multiple models\n",
    "\n",
    "    Args:\n",
    "        model_dir (dir): folder containing the models\n",
    "        num (int): number of models to be loaded from that folder\n",
    "        hp (hp, optional): if model should be loaded based on specific hyper parameter then specify here. Defaults to None.\n",
    "        epoch (int, optional): which epoch of checkpoints to pick from. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        array(models): array of loaded models\n",
    "    \"\"\"\n",
    "    \n",
    "    loaded_models = []\n",
    "    \n",
    "    for i in range(num):        \n",
    "        \n",
    "        if hp:\n",
    "            loaded_model = build_hypermodel(hp)\n",
    "        else:\n",
    "            # Load model configuration\n",
    "            with open(os.path.join(model_dir, f'model_{i}_config.json')) as f:\n",
    "                model_config = json.load(f)\n",
    "\n",
    "            # Recreate the model\n",
    "            loaded_model = Unet_model(3, **model_config)\n",
    "            \n",
    "            loaded_model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanSquaredError()],\n",
    "            )\n",
    "\n",
    "        # Load the weights\n",
    "        if hp:\n",
    "            loaded_model.load_weights(os.path.join(model_dir, f'cp-{epoch:04d}.ckpt'))\n",
    "        else:\n",
    "            loaded_model.load_weights(os.path.join(model_dir, f'model_{i}'))\n",
    "        \n",
    "        loaded_models.append(loaded_model)\n",
    "        \n",
    "        # loaded_model(keras.Input(shape=(16,16,3)), keras.Input(shape=(1,)))\n",
    "        # loaded_model.summary()\n",
    "    \n",
    "    return loaded_models\n",
    "\n",
    "save_dir = current_path.parent.parent / \"weights\"\n",
    "\n",
    "# final_models = load_models(final_models_dir, 5)\n",
    "# final_models2 = load_models(final_models2_dir, 5)\n",
    "# final_models3 = load_models(final_models3_dir, 4)\n",
    "# pre_dropout_models = load_models(pre_dropout_models_dir, 3)\n",
    "# v2_proper_lr = load_models(v2_proper_lr_dir, 5)\n",
    "# trial16 = load_models(\"tuning_results/20240627-230412-v3_Bayesian/trial_16\", 1, hp = best_hps[0], epoch=10)\n",
    "\n",
    "\n",
    "working_model = load_models(save_dir / \"final_model\", 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_ddpm(x, t, pred_noise, z):\n",
    "    noise = tf.sqrt(b_t[t]) * z\n",
    "    mean = (x - pred_noise * ((1 - a_t[t]) / tf.sqrt(1 - ab_t[t]))) / tf.sqrt(a_t[t])\n",
    "    return mean + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_ddpm(model, n_samples, save_rate=20):\n",
    "    # x_T ~ N(0, 1), sample initial noise\n",
    "    samples = tf.random.normal((n_samples, height, height, 3))\n",
    "\n",
    "    # array to keep track of generated steps for plotting\n",
    "    intermediate = [] \n",
    "    for i in range(timesteps, 0, -1):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "\n",
    "        t = tf.constant([i / timesteps], dtype=tf.float32)\n",
    "        z = tf.random.normal(samples.shape) if i > 1 else 0\n",
    "\n",
    "        pred_noise = model(samples, t, training=False)\n",
    "\n",
    "        samples = denoise_ddpm(samples, i, pred_noise, z)\n",
    "        \n",
    "        if i % save_rate==0 or i==timesteps or i<8:\n",
    "            intermediate.append(samples.numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples.numpy(), intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_ddim(x, t, t_prev, pred_noise):\n",
    "    \"\"\"define sampling function for DDIM, removes the noise using ddim\n",
    "    removes predicted noise using noise schedule then adds some noise back\n",
    "\n",
    "    Args:\n",
    "        x (tensor: (batch, h, w, 3)): images to denoise\n",
    "        t (int): current time step\n",
    "        t_prev (int): previous time step\n",
    "        pred_noise (tensor: (batch, h, w, 3)): predicted noise\n",
    "\n",
    "    Returns:\n",
    "        tensor: (batch, h, w, 3): denoised image\n",
    "    \"\"\"\n",
    "    \n",
    "    ab = ab_t[t]\n",
    "    ab_prev = ab_t[t_prev]\n",
    "\n",
    "    x0_pred = tf.sqrt(ab_prev) / tf.sqrt(ab) * (x - tf.sqrt(1 - ab) * pred_noise) # Remove noise from image based on noise schedule DDIM\n",
    "    dir_xt = tf.sqrt(1 - ab_prev) * pred_noise # Add some noise back\n",
    "    \n",
    "    return x0_pred + dir_xt\n",
    "\n",
    "\n",
    "# x = [[[[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]], [[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]]]]\n",
    "# t = 2\n",
    "# t_prev = 1\n",
    "# pred_noise = [[[[0.1, 0.1, 0.1], [0.1, 0.1, 0.1]], [[0.1, 0.1, 0.1], [0.1, 0.1, 0.1]]]]\n",
    "# print(denoise_ddim(x, t, t_prev, pred_noise))\n",
    "# expected_output ISH = [[[[0.45, 0.55, 0.65], [0.45, 0.55, 0.65]], [[0.45, 0.55, 0.65], [0.45, 0.55, 0.65]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBY gotta change t input structure\n",
    "def sampling_DDIM(model, n_samples, n=20):\n",
    "    \"\"\"sampling n images based on diffusion model\n",
    "\n",
    "    Args:\n",
    "        model (tf model): model used to predict noise\n",
    "        n_samples (int): number of images to sample\n",
    "        n (int, optional): total sampling steps to take (DDIM skips steps). Defaults to 20.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = tf.random.normal((n_samples, height, height, 3))\n",
    "    \n",
    "    intermediate = []\n",
    "    stepsize = timesteps // n\n",
    "    for i in range(timesteps, 0, -stepsize):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "        \n",
    "        t = tf.constant([i / timesteps], dtype=tf.float32)\n",
    "\n",
    "        pred_noise = model(samples, t, training=False)\n",
    "        # print(f\"min: {tf.reduce_min(pred_noise)}, max: {tf.reduce_max(pred_noise)}\")\n",
    "        samples = denoise_ddim(samples, i, i-stepsize, pred_noise)\n",
    "        intermediate.append(samples.numpy())\n",
    "    \n",
    "    intermediate = np.array(intermediate)\n",
    "    return samples.numpy(), intermediate\n",
    "\n",
    "samples, intermediate = sampling_DDIM(working_model, 250)\n",
    "print(samples.shape)\n",
    "print(intermediate.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display variables\n",
    "lines_per_model = 8 # how many lines samples to show per model (7 samples per line)\n",
    "\n",
    "show_models = [working_model]\n",
    "\n",
    "samples = []\n",
    "intermediates = []\n",
    "for m in show_models:\n",
    "    # s, i = sampling_DDIM(m, 7*lines_per_model, n = 20)\n",
    "    # samples.append(s)\n",
    "    # intermediates = i\n",
    "    s, i = sampling_ddpm(m, 7*lines_per_model)\n",
    "    samples.append(s)\n",
    "    intermediates = i\n",
    "samples = np.concatenate(samples, axis=0)\n",
    "print(samples.shape)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(lines_per_model*len(show_models),7, figsize=(15,2*lines_per_model*len(show_models)))\n",
    "\n",
    "flattened_axes = axes.flatten()\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = flattened_axes[i]\n",
    "    ax.set_title(f'Model: {(i// (lines_per_model*7) )+1}, Sample: {i+1}')\n",
    "    sample = (sample.clip(-1,1) + 1) / 2 # h,w,3\n",
    "    ax.imshow(sample)\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "fig.show()\n",
    "fig.tight_layout(pad=0)\n",
    "\n",
    "sample = samples[i] # + 1) / 2\n",
    "print(f\"i = {i}, min: {tf.reduce_min(sample)} max: {tf.reduce_max(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, intermediate = sampling_ddpm(working_model, 1000)\n",
    "samples = (samples.clip(-1,1) + 1) / 2\n",
    "\n",
    "print(samples.shape)\n",
    "\n",
    "savepath = current_path.parent.parent / \"generations\" / \"custom_modelV4.npy\"\n",
    "np.save(savepath, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)\n",
    "print(intermediates.shape)\n",
    "\n",
    "def normalize_image_data(images):\n",
    "    # Normalize images from [-1, 1] to [0, 255]\n",
    "    images = ((images.clip(-1,1) + 1) / 2.0) * 255\n",
    "    return images.astype(np.uint8)\n",
    "\n",
    "def resize_image(image, h, w, original = 16):\n",
    "    \n",
    "    tiles_per_row = w // original\n",
    "    tiles_per_col = h // original\n",
    "\n",
    "    # Tiling the image\n",
    "    upscaled_image = np.repeat(np.repeat(image, tiles_per_col, axis=0), tiles_per_row, axis=1)\n",
    "    return upscaled_image\n",
    "\n",
    "def stitch_images(images, grid_shape, image_size, padding, outer_padding):\n",
    "    num_images, _, _, channels = images.shape\n",
    "    rows, cols = grid_shape\n",
    "    \n",
    "    # Calculate the size of the final stitched image including outer padding\n",
    "    stitched_image_size = (\n",
    "        rows * image_size + (rows - 1) * padding + 2 * outer_padding,  # Height with outer padding\n",
    "        cols * image_size + (cols - 1) * padding + 2 * outer_padding,  # Width with outer padding\n",
    "        channels  # Channels (e.g., 3 for RGB)\n",
    "    )\n",
    "    \n",
    "    # Create an empty array for the stitched image with outer padding\n",
    "    stitched_image = np.zeros(stitched_image_size, dtype=np.uint8)\n",
    "    stitched_image.fill(255)  # Fill with white\n",
    "\n",
    "    # Fill the stitched image with the individual images\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            index = i * cols + j\n",
    "            if index < num_images:\n",
    "                # Calculate the position in the final image including outer padding\n",
    "                top = i * (image_size + padding) + outer_padding\n",
    "                left = j * (image_size + padding) + outer_padding\n",
    "                \n",
    "                # Place the image in the stitched image\n",
    "                stitched_image[top:top + image_size, left:left + image_size, :] = images[index]\n",
    "    \n",
    "    return stitched_image\n",
    "\n",
    "# Define grid shape (e.g., 7x5 grid) and other parameters\n",
    "grid_shape = (7, 8)\n",
    "image_size = 64 #target image size per image in the grid\n",
    "padding = 16  # Padding between images\n",
    "outer_padding = 16 # Outer padding around the grid\n",
    "\n",
    "gif_filename = \"generation_process2.gif\"\n",
    "save_path = current_path.parent.parent / \"images\" / gif_filename\n",
    "\n",
    "stitched_images = []\n",
    "for i,images in enumerate(intermediates):\n",
    "    \n",
    "    # Normalize image data\n",
    "    normalized_images = normalize_image_data(images)\n",
    "\n",
    "    # Resize images\n",
    "    resized_images = np.array([resize_image(image, image_size, image_size) for image in normalized_images])\n",
    "\n",
    "    # Stitch images\n",
    "    stitched_image_array = stitch_images(resized_images, grid_shape, image_size, padding, outer_padding)\n",
    "\n",
    "    # Convert the numpy array to an image using PIL\n",
    "    stitched_image = Image.fromarray(stitched_image_array)\n",
    "    stitched_images.append(stitched_image)\n",
    "\n",
    "imageio.mimsave(save_path, stitched_images, format='GIF', duration=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unorm(x):\n",
    "    # unity norm. results in range of [0,1]\n",
    "    # assume x (h,w,3)\n",
    "    xmax = x.max((0,1))\n",
    "    xmin = x.min((0,1))\n",
    "    return(x - xmin)/(xmax - xmin)\n",
    "\n",
    "fig, axes = plt.subplots(15,7, figsize=(15,30))\n",
    "\n",
    "flattened_axes = axes.flatten()\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = flattened_axes[i]\n",
    "    ax.set_title(f'Model: {(i//14)+1}, Sample: {i+1}')\n",
    "    ax.imshow(unorm(sample))\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "fig.show()\n",
    "fig.tight_layout(pad=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
